# ğŸš€ Investigating the Effectiveness of Deep Reinforcement Learning (DRL) in Algorithmic Trading  
ğŸ“Œ **Hackathon: INGENIOUS 6.0**  
ğŸ” **Team Name: 404 Brain Not Found**  

---

## ğŸ“– Table of Contents
- [Introduction](#introduction)
- [Key Features](#key-features)
- [Solution Overview](#solution-overview)
- [Tech Stack](#tech-stack)
- [Market Data Sources](#market-data-sources)
- [Model Training & Implementation](#model-training--implementation)
- [Performance Evaluation](#performance-evaluation)
- [Challenges & Limitations](#challenges--limitations)
- [Future Work](#future-work)
- [Setup & Installation](#setup--installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)

---

## ğŸ“Œ Introduction
Algorithmic trading has advanced with **Deep Reinforcement Learning (DRL)**, enabling adaptive trading strategies.  
This project **evaluates DRL effectiveness** by implementing a **Trading Deep Q-Network (TDQN)** for stock trading.  

### ğŸ”¥ Objective
- Implement a **TDQN-based trading model**.
- Train and test it using **real or simulated market data**.
- Evaluate the modelâ€™s **effectiveness, adaptability, and limitations**.
- Explore if DRL can create **robust trading strategies**.

---

## ğŸŒŸ Key Features
âœ” **DRL-Based Trading Model** â€“ Implements **TDQN** and tests adaptability.  
âœ” **Real-Time Market Data** â€“ Uses **Yahoo Finance API** for stock data.  
âœ” **Performance Metrics** â€“ Evaluates **Sharpe Ratio, ROI**, and risk-adjusted returns.  
âœ” **Market Adaptability** â€“ Analyzes trading behavior in dynamic market conditions.  
âœ” **Flask-Based Trading Bot** â€“ Deploys a web app for real-time trading insights.  
âœ” **Data Visualization** â€“ Uses **Matplotlib, Plotly, and Seaborn** for insights.  

---

## ğŸ›  Solution Overview
ğŸ”¹ **Stock Market Adaptability**  
Tested **TDQN** on real stock data to analyze adaptability to market fluctuations.  

ğŸ”¹ **Reinforcement Learning for Trading**  
- **Agent**: Learns from **historical/live data** to improve trading decisions.  
- **Environment**: Stock market fluctuations (OHLC, volume, economic factors).  
- **Actions**: **Buy**, **Sell**, or **Hold** based on market trends.  
- **Rewards**: **Profit/loss-based feedback** optimizes model learning.  

ğŸ”¹ **Model Implementation**  
- Custom **Gym Environment** for training.  
- **Normalization & Feature Engineering**: RSI, MACD, SMA, MinMaxScaler.  
- **Performance Metrics**: Evaluated using **Sharpe Ratio** & **ROI**.  
- **Flask Deployment** for **real-time predictions**.

---

## ğŸ’» Tech Stack

### **Programming & Libraries**
- Python  
- TensorFlow & PyTorch  
- Stable-Baselines3  
- Gymnasium (Custom Gym Environments)  

### **Data Processing & Feature Engineering**
- Pandas, NumPy  
- Matplotlib, Seaborn, Plotly  
- Scikit-learn, Optuna  
- Log Transformation, MinMaxScaler, XGBoost  

### **Reinforcement Learning Algorithms**
- **Deep Q-Network (DQN)**  
- **Proximal Policy Optimization (PPO)**  

### **Visualization & Web Deployment**
- Flask  
- Plotly & Matplotlib  

---

## ğŸ“Š Market Data Sources
ğŸ“¡ **Yahoo Finance API** â€“ Fetched **15+ years of stock data** for real-time adaptability.  

âœ… **Dataset Includes:**  
- **OHLC (Open, High, Low, Close) Prices**  
- **Trading Volume**  
- **Technical Indicators (RSI, MACD, SMA/EMA)**  

---

## ğŸ— Model Training & Implementation
- **Custom Gym Environment** â€“ Trains TDQN in a simulated trading setup.  
- **Sharpe Ratio & ROI Optimization** â€“ Enhances model performance.  
- **Action Decision Making** â€“ **Buy**, **Sell**, or **Hold** based on stock signals.  
- **Flask Deployment** â€“ Converts AI predictions into a **real-time trading dashboard**.  

ğŸ“Œ **Visualization of Training Progress**:  
![Training Graph](https://github.com/username/repository/blob/main/screenshots/training_graph.png)

---

## ğŸ“ˆ Performance Evaluation
The model was evaluated using **multiple trading strategies**:  
âœ” **Sharpe B&H (Buy & Hold)** â€“ Traditional long-term investment.  
âœ” **Sharpe MR (Mean Reversion)** â€“ Short-term price fluctuations.  
âœ” **Sharpe TDQN** â€“ DRL-based trading model with adaptive decision-making.  

ğŸ”¹ **Performance Metrics Used**:
- **Mean Absolute Error (MAE)**
- **Mean Squared Error (MSE)**
- **Huber Loss**
- **Profit/Loss Analysis**

---

## âš  Challenges & Limitations
ğŸš¨ **Market Volatility & Overfitting Risks**  
- Rapid fluctuations impact **generalization of the model**.  

ğŸš¨ **Reward Engineering Complexity**  
- Defining an **optimal reward function** remains a key challenge.  

ğŸš¨ **Execution Latency**  
- Real-time trading requires **fast decision-making**.  

ğŸš¨ **Data Quality & Feature Selection**  
- The model's accuracy depends on **clean, high-quality financial data**.  

ğŸš¨ **Hyperparameter Sensitivity**  
- Requires **fine-tuning** for optimal learning rates, discount factors, and exploration-exploitation balance.

---

## ğŸš€ Future Work
- **Enhanced Stability** â€“ Using **PPO & A2C** for better convergence.  
- **Real-Time Trading Execution** â€“ Faster decision-making integration.  
- **Multi-Agent Reinforcement Learning** â€“ Smarter trading decisions.  
- **Sentiment Analysis** â€“ Using news data to predict market trends.  
- **Real-Time Dashboards** â€“ Live monitoring of stock performance.  

---

## ğŸ›  Setup & Installation
Clone the repository and install dependencies:

```bash
git clone https://github.com/username/repository.git
cd repository
pip install -r requirements.txt
python app.py
